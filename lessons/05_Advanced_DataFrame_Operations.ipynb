{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1944203",
   "metadata": {},
   "source": [
    "# BME3053C - Computer Applications for BME\n",
    "\n",
    "<br/>\n",
    "\n",
    "<h1 align=\"center\">Advanced DataFrame Operations</h1>\n",
    "\n",
    "---\n",
    "\n",
    "<center><h2>Lesson: 05</h2></center>\n",
    "\n",
    "<br/>\n",
    "\n",
    "<center><img src='https://github.com/snsie/aicc24/blob/main/graphics/pandas_logo.png?raw=1' alt='The Pandas logo' align='center' width=200></center>\n",
    "\n",
    "<br/>\n",
    "\n",
    "### Original Lesson Link: [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/uf-bme/BME3053C-Spring-2025/blob/main/lessons/05_Advanced_DataFrame_Operations.ipynb)\n",
    "\n",
    "### **Covered Topics**\n",
    "\n",
    "1. **Indexing and Iteration**\n",
    "\n",
    "   - Different ways to access data in DataFrames\n",
    "   - Efficient methods for iterating through rows and columns\n",
    "\n",
    "2. **Combining DataFrames**\n",
    "\n",
    "   - Merging DataFrames\n",
    "   - Concatenating DataFrames\n",
    "\n",
    "3. **Data Cleaning**\n",
    "   - Handling missing values and duplicates\n",
    "   - Data type conversion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2558daf",
   "metadata": {},
   "source": [
    "#### Import Pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5eac5a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d459391f",
   "metadata": {},
   "source": [
    "## Indexing and Iteration\n",
    "\n",
    "### Accessing Data in DataFrames\n",
    "\n",
    "- Use `.iloc[]` for integer position-based indexing (e.g., df.iloc[0, 1] for first row, second column)\n",
    "- Use `.loc[]` for label-based indexing (e.g., df.loc['row_label', 'column_name'])\n",
    "\n",
    "- Example:\n",
    "  - df.iloc[0, 1] gets value in first row, second column regardless of labels\n",
    "  - df.loc['A', 'price'] gets value where index='A' and column='price'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53c3f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = {\n",
    "    'A': [1, 2, 3, 4, 5],\n",
    "    'B': [10, 20, 30, 40, 50],\n",
    "    'C': [100, 200, 300, 400, 500]\n",
    "}\n",
    "df = pd.DataFrame(sample_data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e38d7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access first row using integer-based indexing\n",
    "print('\\nFirst row using iloc:')\n",
    "df.iloc[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242aec8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Access first 3 rows and first 3 columns using iloc\n",
    "print('\\nFirst 3 rows and first 3 columns using iloc:')\n",
    "print(df.iloc[0:3, 0:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2160f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access first row using label-based indexing\n",
    "# Note: For this dataset, .loc[] with integer index acts similar to .iloc[] \n",
    "# because the index is numeric and sequential starting from 0\n",
    "\n",
    "print('First row using loc:')\n",
    "print(df.loc[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641aabd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access first 3 rows and specific columns using loc\n",
    "print('\\nFirst 3 rows and selected columns using loc:')\n",
    "print(df.loc[0:2, ['A', 'B']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47e3ed0",
   "metadata": {},
   "source": [
    "### When .loc with integer index differs from .iloc\n",
    "\n",
    "1. **Non-sequential index**: If DataFrame index is not 0,1,2,...\n",
    "\n",
    "   - `.loc[0]` looks for row with index label 0 (may not exist)\n",
    "   - `.iloc[0]` gets first row regardless of its index\n",
    "\n",
    "2. **Non-numeric index**: If DataFrame uses string/date indices\n",
    "\n",
    "   - `.loc[]` won't work with integer input\n",
    "   - `.iloc[]` still works with integer positions\n",
    "\n",
    "3. **Gaps in numeric index**: If index like [0,2,5,...]\n",
    "   - `.loc[1]` looks for index 1 (doesn't exist)\n",
    "   - `.iloc[1]` gets second row (index 2)\n",
    "\n",
    "Example showing difference with non-sequential index:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d911fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "example_df = pd.DataFrame({'A': [1,2,3], 'B': [4,5,6]}, index=[10,20,30])\n",
    "print(\"\\nExample with non-sequential index:\")\n",
    "print(\"Using .loc[10]:\")  # Gets row with index label 10\n",
    "print(example_df.loc[10])\n",
    "print(\"\\nUsing .iloc[0]:\")  # Gets first row regardless of index\n",
    "print(example_df.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4685f406",
   "metadata": {},
   "source": [
    "#### ✏️ **Exercise**\n",
    "\n",
    "1. Create a DataFrame with the following data:\n",
    "   - Columns: 'Name', 'Age', 'City'\n",
    "   - Data: [['Alice', 25, 'New York'], ['Bob', 30, 'Boston'], ['Charlie', 35, 'Chicago']]\n",
    "   - Index: [100, 200, 300]\n",
    "2. Use .loc[] to:\n",
    "   - Get the row with index 200\n",
    "3. Use .iloc[] to:\n",
    "   - Get the first row\n",
    "   - Get the second and third rows with only the 'Name' and 'City' columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2675babd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b55830e5",
   "metadata": {},
   "source": [
    "## Iterating Through Rows and Columns\n",
    "\n",
    "#### Using .iterrows()\n",
    "\n",
    "- Iterates through DataFrame rows as (index, Series) pairs\n",
    "- Each row is returned as a pandas Series object\n",
    "- Useful for row-wise operations\n",
    "- Note: Can be slower than vectorized operations\n",
    "\n",
    "#### Using .items()\n",
    "\n",
    "- Iterates through DataFrame columns as (column_name, Series) pairs\n",
    "- Each column is returned as a pandas Series object\n",
    "- Useful for column-wise operations\n",
    "\n",
    "#### Best Practices:\n",
    "\n",
    "- Use vectorized operations when possible for better performance\n",
    "- Only use iteration when necessary for custom row/column operations\n",
    "- Consider using .apply() as an alternative to explicit loops\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894b3b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    print(f\"Row {index}: {row['A']}\")\n",
    "    if index > 3:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f38e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column_name, column_data in df.items():\n",
    "    if column_name == 'A':  # Stop after mean radius column\n",
    "        print(f\"Column {column_name}: {column_data[0:5]}\")  # Print first value in each column\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdbcdfb",
   "metadata": {},
   "source": [
    "#### ✏️ **Exercise**\n",
    "\n",
    "Create a loop using .items() to find the maximum value in each column of df.\n",
    "Print the column name and its maximum value.\n",
    "\n",
    "- Example output:\n",
    "\n",
    "`A: 5`\n",
    "\n",
    "`B: 50`\n",
    "\n",
    "`C: 500`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bb3688",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2bde1adb",
   "metadata": {},
   "source": [
    "## Combining DataFrames\n",
    "\n",
    "### Concatenating Datasets with pd.concat()\n",
    "\n",
    "- Use `pd.concat()` to stack DataFrames vertically or horizontally\n",
    "- Parameters:\n",
    "  - `axis=0`: Stack vertically (default)\n",
    "  - `axis=1`: Stack horizontally\n",
    "  - `ignore_index`: Reset index after concatenation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4aa4b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample DataFrames\n",
    "df1 = pd.DataFrame({\n",
    "    'A': ['A0', 'A1', 'A2'],\n",
    "    'B': ['B0', 'B1', 'B2']\n",
    "})\n",
    "\n",
    "df2 = pd.DataFrame({\n",
    "    'A': ['A3', 'A4', 'A5'],\n",
    "    'B': ['B3', 'B4', 'B5']\n",
    "})\n",
    "\n",
    "df3 = pd.DataFrame({\n",
    "    'C': ['C0', 'C1', 'C2'],\n",
    "    'D': ['D0', 'D1', 'D2']\n",
    "})\n",
    "\n",
    "print(\"DataFrame 1:\")\n",
    "print(df1)\n",
    "print(\"\\nDataFrame 2:\")\n",
    "print(df2)\n",
    "print(\"\\nDataFrame 3:\")\n",
    "print(df3)\n",
    "\n",
    "# Vertical concatenation (axis=0)\n",
    "vertical_concat = pd.concat([df1, df2])\n",
    "print(\"\\nVertical concatenation (axis=0):\")\n",
    "print(vertical_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15548ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"DataFrame 1:\")\n",
    "print(df1)\n",
    "print(\"\\nDataFrame 2:\")\n",
    "print(df2)\n",
    "# Vertical concatenation with reset index\n",
    "vertical_concat_reset = pd.concat([df1, df2], ignore_index=True)\n",
    "print(\"\\nVertical concatenation with reset index:\")\n",
    "print(vertical_concat_reset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e645c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"DataFrame 1:\")\n",
    "print(df1)\n",
    "\n",
    "print(\"\\nDataFrame 3:\")\n",
    "print(df3)\n",
    "# Horizontal concatenation (axis=1)\n",
    "horizontal_concat = pd.concat([df1, df3], axis=1)\n",
    "print(\"\\nHorizontal concatenation (axis=1):\")\n",
    "print(horizontal_concat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5f7e87",
   "metadata": {},
   "source": [
    "### Merging Datasets with pd.merge()\n",
    "\n",
    "- Use `pd.merge()` to combine DataFrames based on common columns/keys\n",
    "- Similar to SQL JOIN operations\n",
    "- Use `on`: to specify the column(s) to merge on\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c956700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single key merge\n",
    "df1 = pd.DataFrame({'key': ['A', 'B', 'C'], 'columnA': [1, 2, 3]})\n",
    "df2 = pd.DataFrame({'key': ['A', 'B'], 'columnB': [3, 4]})\n",
    "merged_single = pd.merge(df1, df2, on='key')\n",
    "\n",
    "print(\"DataFrame 1:\")\n",
    "print(df1)\n",
    "\n",
    "print(\"\\nDataFrame 2:\")\n",
    "print(df2)\n",
    "\n",
    "print(\"\\nSingle key merge:\")\n",
    "print(merged_single)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f537ceba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple key merge\n",
    "df3 = pd.DataFrame({'ColumnA': ['A', 'B', 'C', 'D'], 'ColumnB': [1, 2, 3, 4], 'ColumnX': [1, 2, 3, 4]})\n",
    "df4 = pd.DataFrame({'ColumnA': ['B', 'C', 'D', 'E'], 'ColumnB': [2, 3, 1, 2], 'ColumnY': [4, 5, 6, 7]})\n",
    "merged_multi = pd.merge(df3, df4, on=['ColumnA', 'ColumnB'])\n",
    "\n",
    "print(\"DataFrame 1:\")\n",
    "print(df3)\n",
    "\n",
    "print(\"\\nDataFrame 2:\")\n",
    "print(df4)\n",
    "\n",
    "print(\"Multiple key merge:\")\n",
    "print(merged_multi)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8db971",
   "metadata": {},
   "source": [
    "#### ✏️ **Exercise**\n",
    "\n",
    "Try to predict the output of the following operations:\n",
    "\n",
    "1. What will happen when we merge these DataFrames?\n",
    "   ```python\n",
    "   df1 = pd.DataFrame({'key': ['A','B'], 'val': [1,2]})\n",
    "   df2 = pd.DataFrame({'key': ['B','C'], 'val': [3,4]})\n",
    "   pd.merge(df1, df2, on='key')\n",
    "   ```\n",
    "2. What will happen when we concatenate the same DataFrames?\n",
    "   ```python\n",
    "   pd.concat([df1, df2])\n",
    "   ```\n",
    "   Key differences to note:\n",
    "\n",
    "- merge: Combines based on matching values in the 'key' column\n",
    "- concat: Simply stacks the DataFrames, keeping all rows\n",
    "  Check your predictions in the next code cell!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5f38f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da106ab8",
   "metadata": {},
   "source": [
    "## Data Cleaning and Preprocessing\n",
    "\n",
    "### Checking for Missing Values\n",
    "\n",
    "- Use `.isna()` or `.isnull()` to check for missing values.\n",
    "- Use `.notna()` or `.notnull()` to check for non-missing values.\n",
    "- Use `.any()` to see if any values are missing in a DataFrame.\n",
    "- Use `.sum()` to count the number of missing values in each column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf83df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_nan = pd.DataFrame({'A': [None, None, 3, 1], 'B': [4, None, None, 33]})\n",
    "df_with_nan.iloc[0, 0] = pd.NA  # Introduce pd.NA to make .isna different from .isnull\n",
    "print(\"DataFrame with NaN, None, and pd.NA values:\")\n",
    "print(df_with_nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3694daa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nCheck for missing values using .isna():\")\n",
    "print(df_with_nan.isna())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141c40e3",
   "metadata": {},
   "source": [
    "isna\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b086fa85",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nCheck for non-missing values using .notna():\")\n",
    "print(df_with_nan.notna())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30aef07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nCheck if any values are missing in the DataFrame using .any():\")\n",
    "print(df_with_nan.isna().any())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78929631",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\nCount the number of missing values in each column using .sum():\")\n",
    "print(df_with_nan.isna().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1368e3b5",
   "metadata": {},
   "source": [
    "### Handling Missing Values\n",
    "\n",
    "- Use `.fillna()` to replace missing values with a specified value.\n",
    "- Use `.dropna()` to remove rows or columns with missing values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67a29cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_nan = pd.DataFrame({'A': [1, None, 3], 'B': [4, 5, None]})\n",
    "filled_df = df_with_nan.fillna(0)\n",
    "print(filled_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf003e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_nan = pd.DataFrame({'A': [1, None, 3], 'B': [4, 5, None]})\n",
    "dropped_df = df_with_nan.dropna()\n",
    "print(dropped_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae2b90c",
   "metadata": {},
   "source": [
    "### Data Type Conversion\n",
    "\n",
    "- Use `.astype()` to convert data types.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199c6a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'A': [1, 2, 3], 'B': [4.0, 5.0, 6.0]})\n",
    "print('before conversion:', df.dtypes)\n",
    "df['A'] = df['A'].astype(float)\n",
    "print('after conversion:', df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5190fff0",
   "metadata": {},
   "source": [
    "#### ✏️ Exercise: DataFrame Treasure Hunt\n",
    "\n",
    "In this exercise, you'll be a data detective on a treasure hunt.\n",
    "Your goal is to clean and preprocess the given DataFrame to uncover hidden treasures (valuable insights).\n",
    "\n",
    "##### Step 1: Create the DataFrame\n",
    "\n",
    "Create a DataFrame with the following data:\n",
    "\n",
    "```python\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', None, 'David', 'Eva'],\n",
    "    'Age': [25, None, 35, 45, None],\n",
    "    'Score': ['85.5', '90.0', None, '088.0', '92.0']\n",
    "}\n",
    "```\n",
    "\n",
    "##### Step 2: Print the person 'Name' with the highest score who isn't missing values in any column\n",
    "\n",
    "**Hint: You can use the [sort_values](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.sort_values.html) method to sort the DataFrame by the 'Score' column.**\n",
    "\n",
    "When sorting values in a DataFrame, the original indices are preserved.\n",
    "If you want to reset the indices after sorting, you can use the reset_index method.\n",
    "\n",
    "For example:\n",
    "\n",
    "```python\n",
    "sorted_df = df.sort_values(by='Column_Name', ascending=False).reset_index(drop=True)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddc3908",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
